"""
ì‘ì—… ë¡œê·¸ ìºì‹œ ê´€ë¦¬ ëª¨ë“ˆ
ë§ˆê° ì²´í‚¹ ì‹œíŠ¸ì˜ ì‘ì—… ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ì—¬ ìºì‹œë¡œ ì €ì¥

í•µì‹¬ ê¸°ëŠ¥:
- worksheet.get_all_values() 1íšŒ/íƒ­ìœ¼ë¡œ API í˜¸ì¶œ ìµœì†Œí™”
- 429/5xx ëŒ€ì‘: ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„
- MID(place_id) ê¸°ë°˜ ì¡°íšŒ ì§€ì› (fallback: business_name)
"""
import os
import json
import time
import hashlib
import re
import logging
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional, Any
import pytz

logger = logging.getLogger(__name__)

# ê¸°ë³¸ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')
CACHE_FILE = os.getenv("WORKLOG_CACHE_FILE", "worklog_cache.json")
CACHE_TTL_HOURS = int(os.getenv("WORKLOG_CACHE_TTL_HOURS", "24"))

# Render Disk ê²½ë¡œ ìš°ì„  ì‚¬ìš©
DISK_PATH = "/var/data"
if os.path.isdir(DISK_PATH):
    DEFAULT_CACHE_PATH = os.path.join(DISK_PATH, "worklog_cache.json")
else:
    DEFAULT_CACHE_PATH = os.path.join(os.getcwd(), "worklog_cache.json")


def _with_retry(func, *args, max_attempts: int = 5, base_delay: float = 1.0, **kwargs):
    """ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ (429/5xx ì™„í™”)"""
    import gspread
    
    for attempt in range(max_attempts):
        try:
            return func(*args, **kwargs)
        except gspread.exceptions.APIError as e:
            status_code = getattr(e, 'response', None)
            if status_code:
                status_code = status_code.status_code
            
            if status_code in (429, 500, 502, 503, 504) and attempt < max_attempts - 1:
                delay = base_delay * (2 ** attempt) + (0.1 * attempt)
                logger.warning(f"API error {status_code}, retry {attempt + 1}/{max_attempts} after {delay:.1f}s")
                time.sleep(delay)
            else:
                raise
        except Exception as e:
            if attempt < max_attempts - 1:
                delay = base_delay * (2 ** attempt)
                logger.warning(f"Error: {e}, retry {attempt + 1}/{max_attempts} after {delay:.1f}s")
                time.sleep(delay)
            else:
                raise
    return None


def extract_mid_from_url(url: str) -> Optional[str]:
    """URLì—ì„œ MID(place_id) ì¶”ì¶œ
    
    Args:
        url: place.naver.com URL
        
    Returns:
        MID ë¬¸ìì—´ (ì˜ˆ: "1234567890") ë˜ëŠ” None
    """
    if not url:
        return None
    
    # place.naver.com/restaurant/1234567890 í˜•ì‹
    match = re.search(r'place\.naver\.com/[^/]+/(\d{5,})', url)
    if match:
        return match.group(1)
    
    # /1234567890 í˜•ì‹ (ìˆ«ìë§Œ)
    match = re.search(r'/(\d{7,})', url)
    if match:
        return match.group(1)
    
    return None


class WorklogCache:
    """ì‘ì—… ë¡œê·¸ ìºì‹œ ê´€ë¦¬ í´ë˜ìŠ¤
    
    ë§ˆê° ì²´í‚¹ ì‹œíŠ¸ì˜ ëª¨ë“  íƒ­ì„ ìŠ¤ìº”í•˜ì—¬ ì •ê·œí™”ëœ ì‘ì—… ë¡œê·¸ë¥¼ ìºì‹œë¡œ ì €ì¥.
    í•™ìŠµìš© ë°ì´í„°ì…‹ ì¡°ì¸ì— í™œìš©.
    """
    
    def __init__(self, cache_file: str = None):
        """ì´ˆê¸°í™”
        
        Args:
            cache_file: ìºì‹œ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: /var/data/worklog_cache.json)
        """
        self.cache_file = cache_file or os.getenv("WORKLOG_CACHE_FILE", DEFAULT_CACHE_PATH)
        self.cache_data = self._load_cache()
    
    def _load_cache(self) -> Dict:
        """ìºì‹œ íŒŒì¼ ë¡œë“œ"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, "r", encoding="utf-8") as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return {
            "updated_at": None,
            "expires_at": None,
            "records": [],
            "stats": {}
        }
    
    def _save_cache(self) -> bool:
        """ìºì‹œ íŒŒì¼ ì €ì¥"""
        try:
            # ë””ë ‰í† ë¦¬ ìƒì„±
            cache_dir = os.path.dirname(self.cache_file)
            if cache_dir and not os.path.exists(cache_dir):
                os.makedirs(cache_dir, exist_ok=True)
            
            with open(self.cache_file, "w", encoding="utf-8") as f:
                json.dump(self.cache_data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            logger.error(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def is_cache_valid(self) -> bool:
        """ìºì‹œê°€ ìœ íš¨í•œì§€ í™•ì¸"""
        if not self.cache_data.get("updated_at"):
            return False
        
        expires_at = self.cache_data.get("expires_at")
        if not expires_at:
            return False
        
        try:
            exp_dt = datetime.fromisoformat(expires_at)
            now = datetime.now(KST)
            if exp_dt.tzinfo is None:
                exp_dt = KST.localize(exp_dt)
            return now < exp_dt
        except Exception:
            return False
    
    def get_cache_status(self) -> Dict:
        """ìºì‹œ ìƒíƒœ ì •ë³´ ì¡°íšŒ"""
        records = self.cache_data.get("records", [])
        
        # íšŒì‚¬ë³„/ì—…ì²´ë³„ í†µê³„
        companies = set()
        businesses = set()
        for r in records:
            if r.get("company"):
                companies.add(r["company"])
            if r.get("business_name"):
                businesses.add(r["business_name"])
        
        return {
            "is_valid": self.is_cache_valid(),
            "updated_at": self.cache_data.get("updated_at"),
            "expires_at": self.cache_data.get("expires_at"),
            "records_count": len(records),
            "companies": list(companies),
            "business_count": len(businesses),
            "stats": self.cache_data.get("stats", {})
        }
    
    def get_worklog_by_business(
        self, 
        business_name: str, 
        date_from: date = None, 
        date_to: date = None
    ) -> List[Dict]:
        """íŠ¹ì • ì—…ì²´ì˜ ì‘ì—… ë¡œê·¸ ì¡°íšŒ
        
        Args:
            business_name: ìƒí˜¸ëª…
            date_from: ì‹œì‘ì¼ (í¬í•¨)
            date_to: ì¢…ë£Œì¼ (í¬í•¨)
            
        Returns:
            í•´ë‹¹ ì—…ì²´ì˜ ì‘ì—… ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for record in self.cache_data.get("records", []):
            if record.get("business_name") != business_name:
                continue
            
            # ë‚ ì§œ í•„í„°ë§
            if date_from or date_to:
                rec_start = record.get("start_date")
                rec_end = record.get("end_date")
                
                if rec_start:
                    try:
                        rec_start_dt = date.fromisoformat(rec_start)
                        if date_to and rec_start_dt > date_to:
                            continue
                    except:
                        pass
                
                if rec_end:
                    try:
                        rec_end_dt = date.fromisoformat(rec_end)
                        if date_from and rec_end_dt < date_from:
                            continue
                    except:
                        pass
            
            results.append(record)
        
        return results
    
    def get_active_tasks_on_date(self, business_name: str, target_date: date) -> List[Dict]:
        """íŠ¹ì • ë‚ ì§œì— í™œì„±í™”ëœ ì‘ì—… ëª©ë¡ ì¡°íšŒ
        
        Args:
            business_name: ìƒí˜¸ëª…
            target_date: ëŒ€ìƒ ë‚ ì§œ
            
        Returns:
            í•´ë‹¹ ë‚ ì§œì— í™œì„± ìƒíƒœì¸ ì‘ì—… ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for record in self.cache_data.get("records", []):
            if record.get("business_name") != business_name:
                continue
            
            # ë‚ ì§œ ë²”ìœ„ í™•ì¸
            start_str = record.get("start_date")
            end_str = record.get("end_date")
            
            try:
                if start_str:
                    start_dt = date.fromisoformat(start_str)
                    if target_date < start_dt:
                        continue
                
                if end_str:
                    end_dt = date.fromisoformat(end_str)
                    if target_date > end_dt:
                        continue
                
                results.append(record)
            except Exception:
                # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ í¬í•¨
                results.append(record)
        
        return results
    
    def get_active_tasks_by_mid(self, mid: str, target_date: date) -> List[Dict]:
        """MID(place_id) ê¸°ì¤€ìœ¼ë¡œ í™œì„± ì‘ì—… ì¡°íšŒ
        
        Args:
            mid: place_id (ìˆ«ì ë¬¸ìì—´)
            target_date: ëŒ€ìƒ ë‚ ì§œ
            
        Returns:
            í•´ë‹¹ ë‚ ì§œì— í™œì„± ìƒíƒœì¸ ì‘ì—… ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for record in self.cache_data.get("records", []):
            rec_mid = record.get("mid")
            if not rec_mid or rec_mid != mid:
                continue
            
            # ë‚ ì§œ ë²”ìœ„ í™•ì¸
            start_str = record.get("start_date")
            end_str = record.get("end_date")
            
            try:
                if start_str:
                    start_dt = date.fromisoformat(start_str)
                    if target_date < start_dt:
                        continue
                
                if end_str:
                    end_dt = date.fromisoformat(end_str)
                    if target_date > end_dt:
                        continue
                
                results.append(record)
            except Exception:
                results.append(record)
        
        return results
    
    def get_active_tasks_smart(
        self, 
        mid: str = None, 
        business_name: str = None, 
        target_date: date = None
    ) -> List[Dict]:
        """MID ìš°ì„ , business_name fallbackìœ¼ë¡œ í™œì„± ì‘ì—… ì¡°íšŒ
        
        Args:
            mid: place_id (ìš°ì„  ì‚¬ìš©)
            business_name: ìƒí˜¸ëª… (MID ì—†ì„ ë•Œ fallback)
            target_date: ëŒ€ìƒ ë‚ ì§œ
            
        Returns:
            í•´ë‹¹ ë‚ ì§œì— í™œì„± ìƒíƒœì¸ ì‘ì—… ë¦¬ìŠ¤íŠ¸
        """
        if not target_date:
            target_date = datetime.now(KST).date()
        
        # 1. MIDë¡œ ë¨¼ì € ì‹œë„
        if mid:
            results = self.get_active_tasks_by_mid(mid, target_date)
            if results:
                return results
        
        # 2. Fallback: business_nameìœ¼ë¡œ ì¡°íšŒ
        if business_name:
            return self.get_active_tasks_on_date(business_name, target_date)
        
        return []
    
    def get_task_totals_on_date(self, business_name: str, target_date: date) -> Dict[str, int]:
        """íŠ¹ì • ë‚ ì§œì˜ ì‘ì—…ë³„ workload í•©ê³„
        
        Returns:
            {"ì‘ì—…ëª…": workloadí•©ê³„, ...}
        """
        tasks = self.get_active_tasks_on_date(business_name, target_date)
        
        totals = {}
        for task in tasks:
            task_name = task.get("task_name", "Unknown")
            try:
                workload = int(task.get("workload", 0) or 0)
            except:
                workload = 0
            
            if task_name in totals:
                totals[task_name] += workload
            else:
                totals[task_name] = workload
        
        return totals
    
    def refresh_cache(self) -> Dict:
        """ì „ì²´ ìºì‹œ ê°±ì‹ 
        
        ë§ˆê° ì²´í‚¹ ì‹œíŠ¸ì˜ ëª¨ë“  íƒ­ì„ ìŠ¤ìº”í•˜ì—¬ ì •ê·œí™”ëœ ì‘ì—… ë¡œê·¸ ìƒì„±
        
        Returns:
            ê°±ì‹  ê²°ê³¼ {"success": bool, "records_count": int, "message": str}
        """
        logger.info("ğŸ”„ Worklog ìºì‹œ ê°±ì‹  ì‹œì‘...")
        start_time = time.time()
        
        try:
            from sheet_client import (
                load_settings, _get_client, _find_header_row, _build_records,
                _get_value_flexible, _normalize_key, _parse_int_maybe
            )
            from internal_manager import _is_internal_or_postpaid, parse_date_flexible
            from guarantee_manager import GuaranteeManager
            
            settings = load_settings()
            if not settings.spreadsheet_id:
                return {"success": False, "records_count": 0, "message": "SPREADSHEET_ID ë¯¸ì„¤ì •"}
            
            client = _get_client()
            
            # ë³´ì¥ê±´ ë°ì´í„°ì—ì„œ íšŒì‚¬-ìƒí˜¸ëª… ë§¤í•‘ ë¡œë“œ
            company_map = {}  # business_name -> company
            guarantee_map = {}  # business_name -> guarantee_item
            try:
                gm = GuaranteeManager()
                for item in gm.get_items():
                    biz = item.get("business_name")
                    if biz:
                        company_map[biz] = item.get("company", "ê¸°íƒ€")
                        guarantee_map[biz] = item
                logger.info(f"ğŸ“‹ ë³´ì¥ê±´ ë§¤í•‘ ë¡œë“œ: {len(company_map)}ê°œ ì—…ì²´")
            except Exception as e:
                logger.warning(f"ë³´ì¥ê±´ ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
            ss = _with_retry(client.open_by_key, settings.spreadsheet_id)
            ws_list = ss.worksheets()
            
            today = datetime.now(KST).date()
            all_records = []
            stats = {
                "worksheets_scanned": 0,
                "worksheets_failed": 0,
                "total_rows": 0,
                "internal_rows": 0,
                "companies": {}
            }
            
            logger.info(f"ğŸ“Š ì›Œí¬ì‹œíŠ¸ {len(ws_list)}ê°œ ìŠ¤ìº” ì‹œì‘")
            
            for idx, ws in enumerate(ws_list, 1):
                tab_title = (ws.title or "").strip()
                
                try:
                    # í—¤ë” ì°¾ê¸°
                    header_row, headers = _find_header_row(ws, settings)
                    
                    # ì „ì²´ ë°ì´í„° 1íšŒ ì½ê¸°
                    records = _with_retry(_build_records, ws, header_row, headers)
                    stats["worksheets_scanned"] += 1
                    stats["total_rows"] += len(records)
                    
                    if idx % 5 == 0 or idx == len(ws_list):
                        logger.info(f"   [{idx}/{len(ws_list)}] {tab_title}: {len(records)}í–‰")
                    
                except Exception as e:
                    logger.warning(f"   [{idx}] {tab_title} ì‹¤íŒ¨: {e}")
                    stats["worksheets_failed"] += 1
                    continue
                
                # ê° í–‰ ì²˜ë¦¬
                for row in records:
                    row_norm = {_normalize_key(k): v for k, v in row.items()}
                    
                    # ë‚´ë¶€ ì§„í–‰ê±´/í›„ë¶ˆ í•„í„°
                    is_internal = _is_internal_or_postpaid(
                        _get_value_flexible(row_norm, settings.internal_col, "INTERNAL_COLUMN")
                    )
                    if not is_internal:
                        continue
                    
                    stats["internal_rows"] += 1
                    
                    # í•„ë“œ ì¶”ì¶œ
                    bizname = str(_get_value_flexible(row_norm, settings.bizname_col, "BIZNAME_COLUMN") or "").strip()
                    if not bizname:
                        continue
                    
                    agency = str(_get_value_flexible(row_norm, settings.agency_col, "AGENCY_COLUMN") or "").strip()
                    workload = str(_get_value_flexible(row_norm, settings.daily_workload_col, "DAILY_WORKLOAD_COLUMN") or "").strip()
                    product = str(_get_value_flexible(row_norm, settings.product_col, "PRODUCT_COLUMN") or "").strip()
                    product_name = str(_get_value_flexible(row_norm, settings.product_name_col, "PRODUCT_NAME_COLUMN") or "").strip()
                    remain = _parse_int_maybe(_get_value_flexible(row_norm, settings.remaining_days_col, "REMAINING_DAYS_COLUMN"))
                    
                    # íšŒì‚¬ ê²°ì •
                    company = company_map.get(bizname, "ê¸°íƒ€")
                    
                    # ì‘ì—…ëª… ìƒì„±
                    if tab_title.lower() == "ê¸°íƒ€" and product_name:
                        task_name = product_name
                    else:
                        task_name = f"{tab_title} {product}".strip() if product else tab_title
                    
                    # ë‚ ì§œ ê³„ì‚°
                    end_date = (today + timedelta(days=remain)).isoformat() if remain is not None else None
                    
                    # ì‘ì—… ì‹œì‘ì¼ ì¶”ì¶œ
                    start_date = None
                    for col in ["ì‘ì—… ì‹œì‘ì¼", "ì‘ì—…ì‹œì‘ì¼", "ì‹œì‘ì¼", "ì„¸íŒ…ì¼"]:
                        val = _get_value_flexible(row_norm, col, "")
                        if val:
                            parsed = parse_date_flexible(str(val).strip())
                            if parsed:
                                start_date = parsed.isoformat()
                                break
                    
                    # URL/MID ì¶”ì¶œ (ìƒˆ ì»¬ëŸ¼)
                    place_url = None
                    mid = None
                    for col in ["URL", "url", "í”Œë ˆì´ìŠ¤ URL", "í”Œë ˆì´ìŠ¤URL", "ì¥ì†Œ URL", "ì¥ì†ŒURL"]:
                        val = _get_value_flexible(row_norm, col, "")
                        if val:
                            place_url = str(val).strip()
                            mid = extract_mid_from_url(place_url)
                            break
                    
                    # MID ì»¬ëŸ¼ ì§ì ‘ ì½ê¸° (URL ì—†ì„ ë•Œ ëŒ€ë¹„)
                    if not mid:
                        for col in ["MID", "mid", "place_id", "í”Œë ˆì´ìŠ¤ID"]:
                            val = _get_value_flexible(row_norm, col, "")
                            if val:
                                mid_str = str(val).strip()
                                if mid_str.isdigit() and len(mid_str) >= 5:
                                    mid = mid_str
                                    break
                    
                    # ë ˆì½”ë“œ ìƒì„±
                    record = {
                        "company": company,
                        "agency": agency,
                        "business_name": bizname,
                        "mid": mid,  # MID ì¶”ê°€
                        "place_url": place_url,  # URL ì¶”ê°€
                        "task_name": task_name,
                        "workload": workload,
                        "start_date": start_date,
                        "end_date": end_date,
                        "source_tab": tab_title,
                    }
                    all_records.append(record)
                    
                    # íšŒì‚¬ë³„ í†µê³„
                    if company not in stats["companies"]:
                        stats["companies"][company] = 0
                    stats["companies"][company] += 1
            
            # ìºì‹œ ì—…ë°ì´íŠ¸
            now = datetime.now(KST)
            expires = now + timedelta(hours=CACHE_TTL_HOURS)
            
            self.cache_data = {
                "updated_at": now.isoformat(),
                "expires_at": expires.isoformat(),
                "records": all_records,
                "stats": stats
            }
            
            if self._save_cache():
                elapsed = time.time() - start_time
                message = f"Worklog ìºì‹œ ê°±ì‹  ì™„ë£Œ - {len(all_records)}ê±´ ({elapsed:.1f}ì´ˆ)"
                logger.info(f"âœ… {message}")
                return {
                    "success": True,
                    "records_count": len(all_records),
                    "message": message,
                    "stats": stats
                }
            else:
                return {"success": False, "records_count": 0, "message": "ìºì‹œ ì €ì¥ ì‹¤íŒ¨"}
            
        except Exception as e:
            logger.error(f"âŒ Worklog ìºì‹œ ê°±ì‹  ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {
                "success": False,
                "records_count": 0,
                "message": f"ê°±ì‹  ì‹¤íŒ¨: {str(e)}"
            }
    
    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.cache_data = {
            "updated_at": None,
            "expires_at": None,
            "records": [],
            "stats": {}
        }
        self._save_cache()
        logger.info("Worklog ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_worklog_cache = None


def get_worklog_cache() -> WorklogCache:
    """WorklogCache ì‹±ê¸€í„´ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _worklog_cache
    if _worklog_cache is None:
        _worklog_cache = WorklogCache()
    return _worklog_cache


def refresh_worklog_cache() -> Dict:
    """Worklog ìºì‹œ ê°±ì‹  (ì™¸ë¶€ í˜¸ì¶œìš©)"""
    cache = get_worklog_cache()
    return cache.refresh_cache()


def get_worklog_cache_status() -> Dict:
    """ìºì‹œ ìƒíƒœ ì¡°íšŒ (ì™¸ë¶€ í˜¸ì¶œìš©)"""
    cache = get_worklog_cache()
    return cache.get_cache_status()
